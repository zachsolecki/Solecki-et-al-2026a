{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "import scipy as sc\n",
    "import os\n",
    "import xarray as xr\n",
    "import tqdm\n",
    "from tqdm import tqdm, trange\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides code to prepare a matrix for the Kmeans clustering algorithm and perform the clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_means = xr.open_dataarray('/path/to/temperature_data.nc') # this is the daily mean temperature data\n",
    "cleaned_clusters03 = np.load('/path/to/masked_real_clean_3.npy') # this is the clearned up CAO binary array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_temperature = all_means.groupby('time.dayofyear').mean('time')\n",
    "anomalies = all_means - mean_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_array, num_features = ndimage.label(cleaned_clusters03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 31/88 [00:21<00:39,  1.44it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):  \u001b[38;5;66;03m# Start from 1 as 0 is background label\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Find the indices where the labeled feature is present in the first slice\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     indices_start \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(labeled_array \u001b[38;5;241m==\u001b[39m label)\n\u001b[0;32m---> 12\u001b[0m     first_slice_index \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_start\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     first_slice \u001b[38;5;241m=\u001b[39m labeled_array[first_slice_index]\n\u001b[1;32m     14\u001b[0m     start_ys_zs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(first_slice \u001b[38;5;241m==\u001b[39m label)\n",
      "File \u001b[0;32m/glade/work/zsolecki/miniconda3/envs/research/lib/python3.12/site-packages/numpy/core/fromnumeric.py:2953\u001b[0m, in \u001b[0;36mmin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2836\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_min_dispatcher)\n\u001b[1;32m   2837\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2838\u001b[0m         where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2839\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2840\u001b[0m \u001b[38;5;124;03m    Return the minimum of an array or minimum along an axis.\u001b[39;00m\n\u001b[1;32m   2841\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2951\u001b[0m \u001b[38;5;124;03m    6\u001b[39;00m\n\u001b[1;32m   2952\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2953\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2954\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/zsolecki/miniconda3/envs/research/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create arrays to store the centroids\n",
    "start_centroids = np.zeros((num_features, 2))  # (y, z) for the first slice\n",
    "end_centroids = np.zeros((num_features, 2))    # (y, z) for the last slice\n",
    "\n",
    "# Create an array to store the distances\n",
    "horizontal_distances = np.zeros(num_features)\n",
    "\n",
    "# Iterate through each labeled feature\n",
    "for label in tqdm(range(1, num_features + 1)):  # Start from 1 as 0 is background label\n",
    "    # Find the indices where the labeled feature is present in the first slice\n",
    "    indices_start = np.where(labeled_array == label)\n",
    "    first_slice_index = np.min(indices_start[0])\n",
    "    first_slice = labeled_array[first_slice_index]\n",
    "    start_ys_zs = np.where(first_slice == label)\n",
    "\n",
    "    # Find the centroid in the first slice\n",
    "    start_centroids[label - 1] = [np.mean(start_ys_zs[0]), np.mean(start_ys_zs[1])]\n",
    "\n",
    "    # Find the indices where the labeled feature is present in the last slice\n",
    "    indices_end = np.where(labeled_array == label)\n",
    "    last_slice_index = np.max(indices_end[0])\n",
    "    last_slice = labeled_array[last_slice_index]\n",
    "    end_ys_zs = np.where(last_slice == label)\n",
    "\n",
    "    # Find the centroid in the last slice\n",
    "    end_centroids[label - 1] = [np.mean(end_ys_zs[0]), np.mean(end_ys_zs[1])]\n",
    "\n",
    "    # Calculate the horizontal distance between the starting and ending centroids for each feature\n",
    "    horizontal_distances[label - 1] = np.linalg.norm(start_centroids[label - 1] - end_centroids[label - 1])\n",
    "\n",
    "# Now, 'horizontal_distances' contains the horizontal distances between the starting and ending centroids for each labeled feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_start = np.where(labeled_array == 32)\n",
    "first_slice_index = np.min(indices_start[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2631"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_slice_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_x = start_centroids[:, 0]\n",
    "start_y = start_centroids[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = []\n",
    "\n",
    "for label in tqdm(range(1, num_features + 1)):\n",
    "    indices = np.where(labeled_array == label)\n",
    "    if indices[0].size > 0:\n",
    "        depth = np.max(indices[0]) - np.min(indices[0]) + 1\n",
    "        depths.append(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalized anomalies\n",
    "import numpy as np\n",
    "\n",
    "std_temps = np.std(anomalies, axis=0)\n",
    "mean = np.mean(anomalies, axis=0)\n",
    "\n",
    "normalized_anomalies = (anomalies - mean) / std_temps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "average_normalized_anomalies = np.zeros(num_features)\n",
    "centroid_max_intensity = np.zeros((num_features, 2))\n",
    "max_extent2 = []\n",
    "# Iterate through each labeled feature\n",
    "for label in tqdm(range(1, num_features + 1)):  # Start from 1 as 0 is background label\n",
    "    # Find the indices where the labeled feature is present\n",
    "    indices = np.where(labeled_array == label)\n",
    "    extent = []\n",
    "    for i in np.unique(indices[0]):\n",
    "        extent.append(np.sum(labeled_array[i]) / label)\n",
    "        max_extent = np.argmax(extent)\n",
    "        max_extent_i = max_extent + np.unique(indices[0])[0]\n",
    "    max_extent2.append(np.max(extent))\n",
    "    intense_slice = labeled_array[max_extent_i]\n",
    "    ys_zs = np.where(intense_slice == label)\n",
    "    centroid_max_intensity[label - 1] = [np.mean(ys_zs[0]), np.mean(ys_zs[1])]\n",
    "\n",
    "    # Extract the normalized anomalies for the labeled feature using the unique indices\n",
    "    for i in range(len(ys_zs[0])):\n",
    "        anomalies_for_feature = []\n",
    "        anomalies_for_feature.append(anomalies[max_extent_i][ys_zs[0][i]][ys_zs[1][i]])\n",
    "\n",
    "\n",
    "    # Calculate the average normalized anomaly for the labeled feature\n",
    "    average_normalized_anomaly = np.mean(anomalies_for_feature)\n",
    "\n",
    "    # Store the result in the array\n",
    "    average_normalized_anomalies[label - 1] = average_normalized_anomaly\n",
    "\n",
    "# Now, 'average_normalized_anomalies' contains the average normalized anomalies for each labeled feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(max_extent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_temps = np.mean(average_normalized_anomalies)\n",
    "std_temps = np.std(average_normalized_anomalies)\n",
    "normalized_anomalies = (average_normalized_anomalies - mean_temps) / std_temps\n",
    "\n",
    "mean_extent = np.mean(max_extent2)\n",
    "std_extent = np.std(max_extent2)\n",
    "normalized_extent = (max_extent2 - mean_extent) / std_extent\n",
    "\n",
    "mean_distances = np.mean(horizontal_distances)\n",
    "std_distances = np.std(horizontal_distances)\n",
    "normalized_distances = (horizontal_distances - mean_distances) / std_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/glade/work/zsolecki/arrays/normalized_anomalies.npy', normalized_anomalies)\n",
    "np.save('/glade/work/zsolecki/arrays/normalized_distances.npy', normalized_distances)\n",
    "np.save('/glade/work/zsolecki/arrays/normalized_extent.npy', normalized_extent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_x = centroid_max_intensity[:, 0]\n",
    "centroid_y = centroid_max_intensity[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_x = np.mean(centroid_x)\n",
    "std_x = np.std(centroid_x)\n",
    "normalized_x = (centroid_x - mean_x) / std_x\n",
    "\n",
    "mean_y = np.mean(centroid_y)\n",
    "std_y = np.std(centroid_y)\n",
    "normalized_y = (centroid_y - mean_y) / std_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/glade/work/zsolecki/CAO_project/arrays/normalized_x_new.npy', centroid_x)\n",
    "np.save('/glade/work/zsolecki/CAO_project/arrays/notmalized_y_new.npy', centroid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed = horizontal_distances / depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_speed = np.mean(speed)\n",
    "std_speed = np.std(speed)\n",
    "normalized_speed = (speed - mean_speed) / std_speed\n",
    "np.save('/glade/work/zsolecki/arrays/normalized_speed.npy', normalized_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes = []\n",
    "for label in tqdm(range(1, num_features + 1)):\n",
    "    volume = np.sum(labeled_array == label)\n",
    "    volumes.append(volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_volumes = np.mean(volumes)\n",
    "std_volumes = np.std(volumes)\n",
    "normalized_volumes = (volumes - mean_volumes) / std_volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/glade/work/zsolecki/arrays/normalized_volumes.npy', normalized_volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = np.column_stack((\n",
    "    normalized_volumes,\n",
    "    normalized_distances,\n",
    "    normalized_extent,\n",
    "    normalized_anomalies,\n",
    "    normalized_speed,\n",
    "    normalized_x,\n",
    "    normalized_y\n",
    "))\n",
    "\n",
    "np.save('../data/feature_matrix.npy', feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "optimal_k = 5  # Replace with your optimal number of clusters\n",
    "\n",
    "# Initialize KMeans with the optimal number of clusters\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "\n",
    "# Fit KMeans to your feature matrix\n",
    "cluster_labels = kmeans.fit_predict(feature_matrix)\n",
    "\n",
    "# Add the cluster labels as a new column in your feature matrix\n",
    "feature_matrix_with_clusters = np.column_stack((feature_matrix, cluster_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = feature_matrix_with_clusters[:, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_0 = np.where(clusters == 0)[0]\n",
    "indices_1 = np.where(clusters == 1)[0]\n",
    "indices_2 = np.where(clusters == 2)[0]\n",
    "indices_3 = np.where(clusters == 3)[0]\n",
    "indices_4 = np.where(clusters == 4)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_0 = np.array(volumes)[indices_0]\n",
    "volume_1 = np.array(volumes)[indices_1]\n",
    "volume_2 = np.array(volumes)[indices_2]\n",
    "volume_3 = np.array(volumes)[indices_3]\n",
    "volume_4 = np.array(volumes)[indices_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extent_0 = np.array(max_extent2)[indices_0]\n",
    "extent_1 = np.array(max_extent2)[indices_1]\n",
    "extent_2 = np.array(max_extent2)[indices_2]\n",
    "extent_3 = np.array(max_extent2)[indices_3]\n",
    "extent_4 = np.array(max_extent2)[indices_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_0 = np.array(speed)[indices_0]\n",
    "speed_1 = np.array(speed)[indices_1]\n",
    "speed_2 = np.array(speed)[indices_2]\n",
    "speed_3 = np.array(speed)[indices_3]\n",
    "speed_4 = np.array(speed)[indices_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_0 = np.array(average_normalized_anomalies)[indices_0]\n",
    "anomalies_1 = np.array(average_normalized_anomalies)[indices_1]\n",
    "anomalies_2 = np.array(average_normalized_anomalies)[indices_2]\n",
    "anomalies_3 = np.array(average_normalized_anomalies)[indices_3]\n",
    "anomalies_4 = np.array(average_normalized_anomalies)[indices_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_0 = np.array(horizontal_distances)[indices_0]\n",
    "distances_1 = np.array(horizontal_distances)[indices_1]\n",
    "distances_2 = np.array(horizontal_distances)[indices_2]\n",
    "distances_3 = np.array(horizontal_distances)[indices_3]\n",
    "distances_4 = np.array(horizontal_distances)[indices_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = np.array(centroid_x)[indices_0]\n",
    "x_1 = np.array(centroid_x)[indices_1]\n",
    "x_2 = np.array(centroid_x)[indices_2]\n",
    "x_3 = np.array(centroid_x)[indices_3]\n",
    "x_4 = np.array(centroid_x)[indices_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_0 = np.array(centroid_y)[indices_0]\n",
    "y_1 = np.array(centroid_y)[indices_1]\n",
    "y_2 = np.array(centroid_y)[indices_2]\n",
    "y_3 = np.array(centroid_y)[indices_3]\n",
    "y_4 = np.array(centroid_y)[indices_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_0 = np.column_stack((\n",
    "    volume_0,\n",
    "    distances_0,\n",
    "    extent_0,\n",
    "    anomalies_0,\n",
    "    speed_0,\n",
    "    x_0,\n",
    "    y_0, \n",
    "    indices_0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_1 = np.column_stack((\n",
    "    volume_1,\n",
    "    distances_1,\n",
    "    extent_1,\n",
    "    anomalies_1,\n",
    "    speed_1,\n",
    "    x_1,\n",
    "    y_1,\n",
    "    indices_1\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_2 = np.column_stack((\n",
    "    volume_2,\n",
    "    distances_2,\n",
    "    extent_2,\n",
    "    anomalies_2,\n",
    "    speed_2,\n",
    "    x_2,\n",
    "    y_2,\n",
    "    indices_2\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_3 = np.column_stack((\n",
    "    volume_3,\n",
    "    distances_3,\n",
    "    extent_3,\n",
    "    anomalies_3,\n",
    "    speed_3,\n",
    "    x_3,\n",
    "    y_3,\n",
    "    indices_3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_4 = np.column_stack((\n",
    "    volume_4,\n",
    "    distances_4,\n",
    "    extent_4,\n",
    "    anomalies_4,\n",
    "    speed_4,\n",
    "    x_4,\n",
    "    y_4,\n",
    "    indices_4\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/glade/work/zsolecki/arrays/matrix_0.npy', matrix_0)\n",
    "np.save('/glade/work/zsolecki/arrays/matrix_1.npy', matrix_1)\n",
    "np.save('/glade/work/zsolecki/arrays/matrix_2.npy', matrix_2)\n",
    "np.save('/glade/work/zsolecki/arrays/matrix_3.npy', matrix_3)\n",
    "np.save('/glade/work/zsolecki/arrays/matrix_4.npy', matrix_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-research]",
   "language": "python",
   "name": "conda-env-miniconda3-research-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
